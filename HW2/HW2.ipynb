{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGSE Text Mining Homework 2\n",
    "### Euan Dowers, Veronika Kyuchukova, and Laura Roman\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "The object of this exercise is to implement uncollapsed gibbs sampling for fitting an LDA model to state of the union speeches from 1945 onwards, with documents being defined at the paragraph level. \n",
    "\n",
    "First, we need to read in and process the data, as in the first homework set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import sys\n",
    "import scipy.sparse as ssp\n",
    "import time\n",
    "import matplotlib\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from numpy.random import dirichlet\n",
    "from collections import Counter\n",
    "from utils import data_processing, get_vocab, make_count\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.9 s, sys: 16 ms, total: 8.92 s\n",
      "Wall time: 8.92 s\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_table(\"HW1/speech_data_extend.txt\",encoding=\"utf-8\")\n",
    "data_post1945 = data.loc[data.year >= 1945]\n",
    "%time stemmed, processed_data = data_processing(data_post1945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a function that implements uncollapsed gibbs sampling on our processed data.\n",
    "This essentially works by repeatedly sampling from the posterior distributions of $Z$, $\\Theta$, and $\\beta$ and updating values using the most recent sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Gibbs_sampling_LDA(stemmed, K, alpha = None, eta = None, m=3, n_samples = 200, burnin = 500, perplexity = False):\n",
    "    '''\n",
    "    Gibbs sampler for LDA model\n",
    "    '''\n",
    "\n",
    "    def Z_class_1(Beta, Theta):\n",
    "        Z = [np.ndarray.tolist( np.argmax( Beta[:,[idx[word] for word in stemmed[i]]] * \\\n",
    "        Theta[i,:].reshape((K, 1)), axis = 0) ) for i in range(Theta.shape[0] )]\n",
    "        return Z\n",
    "\n",
    "    def Beta_sample(eta, Z):\n",
    "        z_s = [z for sublist in Z for z in sublist ]\n",
    "        M = np.zeros(shape=(K,V))\n",
    "        for k in range(K):\n",
    "            words = [s[i] for i in range(len(z_s)) if z_s[i] == k]\n",
    "            counts = Counter(words)\n",
    "            for word in set(words):\n",
    "                M[k,idx[word]] = counts[word]\n",
    "        Beta = [dirichlet(alpha = eta + M[i],size = 1)[0] for i in range(K)]\n",
    "        return np.array(Beta)\n",
    "\n",
    "    def Theta_sample(alpha, Z):\n",
    "        N   = np.zeros(shape=(D,K))\n",
    "        for i in range(D):\n",
    "            counts   = Counter(Z[i])\n",
    "            for j in set(counts.keys()):\n",
    "                N[i,j]  = counts[j]\n",
    "        Theta = [dirichlet(alpha = alpha + N[i],size = 1)[0] for i in range(D)]\n",
    "        return np.array(Theta)\n",
    "\n",
    "    def onehotencode(Z):\n",
    "        '''\n",
    "        Create function to one-hot encode topic allocation\n",
    "        '''\n",
    "        a       = np.array([i for sublist in Z for i in sublist ])\n",
    "        b       = np.zeros((a.size, a.max()+1))\n",
    "        b[np.arange(a.size),a] = 1\n",
    "        return(b)\n",
    "\n",
    "    def perplexity(Theta, Beta, count_matrix):\n",
    "        '''\n",
    "        Calculate perplexity for given sample\n",
    "        '''\n",
    "        ltb     = np.log(Theta.dot(Beta))\n",
    "        num     = np.sum(count_matrix.multiply(ltb))\n",
    "        denom   = len(s)\n",
    "        return np.exp(-num/denom)\n",
    "\n",
    "    # Get params needed for passing to sampling functions\n",
    "    s       = [i for sublist in stemmed for i in sublist ]\n",
    "    vocab   = get_vocab(stemmed)\n",
    "    D       = len(stemmed)\n",
    "    V       = len(vocab)\n",
    "    idx     = dict(zip(vocab,range(len(vocab))))\n",
    "    count_matrix = make_count(stemmed, idx)\n",
    "    perp   = []\n",
    "\n",
    "    # Initialise params\n",
    "    if eta == None:\n",
    "        eta = 200/V\n",
    "    if alpha == None:\n",
    "        alpha = 50/K\n",
    "\n",
    "    Theta   = dirichlet(alpha = [alpha]*K, size = D)\n",
    "    Beta    = dirichlet(alpha = [eta]*V, size = K)\n",
    "    Z       = Z_class_1(Beta, Theta)\n",
    "    labels  = np.zeros((n_samples, len(s)))\n",
    "\n",
    "    # SAMPLING\n",
    "    print('TIME:', time.strftime(\"%H:%M:%S\", time.gmtime()))\n",
    "    for i in tqdm(range(burnin)):\n",
    "        Z       = Z_class_1(Beta, Theta)\n",
    "        Beta    = Beta_sample(eta, Z)\n",
    "        Theta   = Theta_sample(alpha, Z)\n",
    "        if i%20 == 0:\n",
    "            if perplexity:\n",
    "                perp.append(perplexity(Theta, Beta, count_matrix))\n",
    "            #print('Burnin iteration {}'.format(i))\n",
    "\n",
    "    print('TIME:', time.strftime(\"%H:%M:%S\", time.gmtime()))\n",
    "    for i in tqdm(range(m*n_samples)):\n",
    "        Z       = Z_class_1(Beta, Theta)\n",
    "        Beta    = Beta_sample(eta, Z)\n",
    "        Theta   = Theta_sample(alpha, Z)\n",
    "\n",
    "        # Add every m-th sample to output\n",
    "        if i%m == 0:\n",
    "            Z_s = [i for sublist in Z for i in sublist ]\n",
    "            j = np.int(i/m)\n",
    "            labels[j, :] = Z_s\n",
    "        if i%20 == 0:\n",
    "            if perplexity:\n",
    "                perp.append(perplexity(Theta, Beta, count_matrix))\n",
    "            #print( \"Iteration {}\".format(i))\n",
    "\n",
    "    return (labels, perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 10:31:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [14:24<00:00,  1.38it/s]\n",
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: 10:46:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [22:28<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "LDA_labels, perp = Gibbs_sampling_LDA(stemmed,\n",
    "                                      K = 10,\n",
    "                                      n_samples = 500,\n",
    "                                      perplexity=True,\n",
    "                                      burnin = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see this sampling function takes around 35 minutes to complete 2500 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
